import streamlit as st
import pandas as pd
from core.database import (
    get_db_connection,
    find_next_merge_candidate_group,
    get_patterns_data_by_ids,
    execute_multiple_merges,
    mark_patterns_as_skipped,
    get_available_lengths_for_merging
)

st.set_page_config(page_title="–°–ª–∏—è–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤", layout="wide")

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è ---
if 'current_merge_group' not in st.session_state:
    st.session_state.current_merge_group = None
if 'planned_merges' not in st.session_state:
    st.session_state.planned_merges = []
if 'selected_length' not in st.session_state:
    st.session_state.selected_length = None

conn = get_db_connection()

# --- –§—É–Ω–∫—Ü–∏–∏-–ø–æ–º–æ—â–Ω–∏–∫–∏ –¥–ª—è UI ---
def add_merge_to_plan():
    source_ids = st.session_state.get('merge_source_select', [])
    target_id = st.session_state.get('merge_target_select')
    if not source_ids or not target_id:
        st.warning("–ù—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –∏ –∏—Å—Ö–æ–¥–Ω—ã–µ, –∏ —Ü–µ–ª–µ–≤–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω—ã.")
        return
    if target_id in source_ids:
        st.error("–¶–µ–ª–µ–≤–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∏ –∏—Å—Ö–æ–¥–Ω—ã–º.")
        return
    
    all_planned_ids = {p_id for merge in st.session_state.planned_merges for p_id in merge['sources']} \
                    | {merge['target'] for merge in st.session_state.planned_merges}
    
    if any(pid in all_planned_ids for pid in source_ids) or target_id in all_planned_ids:
        st.error("–û–¥–∏–Ω –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —É–∂–µ —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ –¥—Ä—É–≥–æ–º –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Å–ª–∏—è–Ω–∏–∏.")
        return

    st.session_state.planned_merges.append({
        "sources": source_ids,
        "target": target_id
    })

def clear_plan():
    st.session_state.planned_merges = []

def clear_current_group():
    st.session_state.current_merge_group = None
    st.session_state.planned_merges = []

# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ --- #
st.title("–°–ª–∏—è–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
st.warning("**–í–Ω–∏–º–∞–Ω–∏–µ!** –≠—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª –≤—ã–ø–æ–ª–Ω—è–µ—Ç –Ω–µ–æ–±—Ä–∞—Ç–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")

available_lengths = get_available_lengths_for_merging(conn)
st.selectbox(
    "–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–ª–∏–Ω—ã:", 
    options=available_lengths, 
    key='selected_length', 
    index=None, 
    placeholder="–í—ã–±–µ—Ä–∏—Ç–µ –¥–ª–∏–Ω—É...",
    on_change=clear_current_group # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—É –ø—Ä–∏ —Å–º–µ–Ω–µ –¥–ª–∏–Ω—ã
)

# –®–∞–≥ 2: –ú–æ–¥–µ—Ä–∞—Ü–∏—è –≥—Ä—É–ø–ø—ã
if st.session_state.selected_length:

    if not st.session_state.current_merge_group:
        with st.spinner(f"–ò–¥–µ—Ç –ø–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª–∏–Ω–æ–π {st.session_state.selected_length}..."):
            st.session_state.current_merge_group = find_next_merge_candidate_group(conn, st.session_state.selected_length)

    if not st.session_state.current_merge_group:
        st.success(f"‚úÖ –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –¥–ª—è –¥–ª–∏–Ω—ã {st.session_state.selected_length} –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
    else:
        group = st.session_state.current_merge_group
        pattern_ids = group['pattern_ids']
        
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤..."):
            patterns_data = get_patterns_data_by_ids(conn, pattern_ids)
            patterns_map = {p['id']: p for p in patterns_data}

        st.markdown("---")

        # --- –õ–æ–≥–∏–∫–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏ –≤—ã–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–∏–π ---
        num_tokens = st.session_state.selected_length
        keys = ['dep', 'pos', 'tag']
        parsed_patterns = {}

        # –®–∞–≥ 1: –†–∞–∑–æ–±—Ä–∞—Ç—å –≤—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –≥—Ä—É–ø–ø–µ
        for p in patterns_data:
            all_parts = p['text'].split('_')
            if len(all_parts) >= num_tokens * 3:
                parsed_patterns[p['id']] = {
                    'dep': all_parts[0:num_tokens],
                    'pos': all_parts[num_tokens:num_tokens*2],
                    'tag': all_parts[num_tokens*2:num_tokens*3]
                }
            else:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—ã—Ä–æ–º –≤–∏–¥–µ, –µ—Å–ª–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å
                parsed_patterns[p['id']] = {'raw': p['text']}

        # –®–∞–≥ 2: –ù–∞–π—Ç–∏ –∏–Ω–¥–µ–∫—Å—ã, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —Ä–∞–∑–ª–∏—á–∏—è
        diff_indices = {key: set() for key in keys}
        if len(patterns_data) > 1:
            for key in keys:
                for i in range(num_tokens):
                    # –°–æ–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –¥–∞–Ω–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏ —É –≤—Å–µ—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                    values = set()
                    for p in patterns_data:
                        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø–∞—Ç—Ç–µ—Ä–Ω –±—ã–ª —Ä–∞–∑–æ–±—Ä–∞–Ω –∏ –∏–º–µ–µ—Ç –Ω—É–∂–Ω—ã–π –∫–ª—é—á –∏ –∏–Ω–¥–µ–∫—Å
                        if 'raw' not in parsed_patterns[p['id']] and i < len(parsed_patterns[p['id']][key]):
                            values.add(parsed_patterns[p['id']][key][i])
                    
                    # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–π –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ, –∑–Ω–∞—á–∏—Ç, –µ—Å—Ç—å —Ä–∞–∑–ª–∏—á–∏–µ
                    if len(values) > 1:
                        diff_indices[key].add(i)
        # --- –ö–æ–Ω–µ—Ü –ª–æ–≥–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è ---

        patterns_per_row = 3
        chunked_patterns = [patterns_data[i:i + patterns_per_row] for i in range(0, len(patterns_data), patterns_per_row)]

        for row_patterns in chunked_patterns:
            cols = st.columns(patterns_per_row)
            for i, p_data in enumerate(row_patterns):
                with cols[i]:
                    st.subheader(f"–ü–∞—Ç—Ç–µ—Ä–Ω #{p_data['id']}")

                    # --- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∞ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º ---
                    current_parsed = parsed_patterns.get(p_data['id'])
                    if not current_parsed or 'raw' in current_parsed:
                        # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–µ –±—ã–ª —Ä–∞–∑–æ–±—Ä–∞–Ω, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                        st.code(p_data['text'], language='bash')
                    else:
                        lines_for_code = []
                        for key in keys:
                            line_parts = []
                            for idx, token in enumerate(current_parsed[key]):
                                if idx in diff_indices[key]:
                                    line_parts.append(f"[{token}]") # –í—ã–¥–µ–ª—è–µ–º —Å–∫–æ–±–∫–∞–º–∏
                                else:
                                    line_parts.append(token)
                            lines_for_code.append("_".join(line_parts))
                        
                        code_string = "\n".join(lines_for_code)
                        st.code(code_string, language='bash')
                    # --- –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è ---

                    st.markdown(f"**F:** {p_data['freq']:.2f} | **Q:** {p_data['qty']}")
                    if p_data['examples']:
                        df_examples = pd.DataFrame(p_data['examples'])
                        df_examples.rename(columns={'text': '–§—Ä–∞–∑–∞', 'freq': '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å (ipm)'}, inplace=True)
                        st.dataframe(df_examples, hide_index=True, use_container_width=True)
                    else:
                        st.write("–ü—Ä–∏–º–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

        with st.container(border=True):
            col1, col2, col3 = st.columns([2, 2, 1])
            with col1:
                target_select = st.selectbox("–û—Å–Ω–æ–≤–Ω–æ–π", options=list(patterns_map.keys()), format_func=lambda pid: f"#{pid}: {patterns_map[pid]['text']}", key="merge_target_select", index=None)
            with col2:
                source_select = st.multiselect("–ü–æ–≥–ª–æ—â–∞–µ–º—ã–π", options=list(patterns_map.keys()), format_func=lambda pid: f"#{pid}: {patterns_map[pid]['text']}", key="merge_source_select")
            with col3:
                st.write("")
                st.button("–î–æ–±–∞–≤–∏—Ç—å –≤ –ø–ª–∞–Ω", on_click=add_merge_to_plan, use_container_width=True)

        if st.session_state.planned_merges:
            st.subheader("–ü–ª–∞–Ω —Å–ª–∏—è–Ω–∏—è –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã")
            for i, merge in enumerate(st.session_state.planned_merges):
                with st.container(border=True):
                    st.write(f"**–û–ø–µ—Ä–∞—Ü–∏—è #{i+1}**")
                    target_text = patterns_map[merge['target']]['text']
                    st.write(f"üéØ **–¶–µ–ª—å:** `#{merge['target']}`: *{target_text}*")
                    st.write("**–ò—Å—Ç–æ—á–Ω–∏–∫–∏ (–±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏ –∑–∞–º–µ–Ω–µ–Ω—ã):**")
                    for source_id in merge['sources']:
                        source_text = patterns_map[source_id]['text']
                        st.write(f"- `#{source_id}`: *{source_text}*")
            st.button("–û—á–∏—Å—Ç–∏—Ç—å –ø–ª–∞–Ω", on_click=clear_plan, use_container_width=True)

        st.markdown("---")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("‚úÖ –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å–µ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª–∏—è–Ω–∏—è", use_container_width=True, type="primary", disabled=not st.session_state.planned_merges):
                with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–ª–∏—è–Ω–∏–µ... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏."):
                    success, message = execute_multiple_merges(conn, st.session_state.planned_merges)
                    if success:
                        st.success(f"–°–ª–∏—è–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! {message}")
                        clear_current_group()
                        st.rerun()
                    else:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–ª–∏—è–Ω–∏–∏: {message}")

        with col2:
            if st.button("‚û°Ô∏è –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç—É –≥—Ä—É–ø–ø—É –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤", use_container_width=True):
                with st.spinner("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤..."):
                    group_info = st.session_state.current_merge_group
                    diff_level = group_info.get("difference_level", 0)
                    diff_types = group_info.get("difference_types", [])
                    
                    mark_patterns_as_skipped(conn, pattern_ids, diff_level, diff_types)

                st.success(f"–ì—Ä—É–ø–ø–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞ (—É—Ä–æ–≤–µ–Ω—å: {diff_level}, —Ç–∏–ø—ã: {diff_types}). –ü–∞—Ç—Ç–µ—Ä–Ω—ã {pattern_ids} –±–æ–ª—å—à–µ –Ω–µ –±—É–¥—É—Ç –ø–æ—è–≤–ª—è—Ç—å—Å—è –≤ –ø–æ–¥–æ–±–Ω—ã—Ö –ø–æ–∏—Å–∫–∞—Ö.")
                clear_current_group()
                st.rerun()